# SRGANAssignment5Midterm
This repository is for Matthew Sanchez and the assignment submission for ECGR 4090. This is the location for the .ipynb of the code as well as the outputs from this code. 
Assignment 5 Midterm Exam 
By: Matthew Sanchez
ECGR 4090

This purpose of this assingment was to build a Generative Adversarial Network (GAN) and use it to generate high resolution images on the binary classification problem from Assignment 1. The data that is used is a collection of Kaggle Retinal OCT Images found on the UNCC 4090 Canvas site. The version that has been used is the tiny version of the dataset containing 3048 images which are divided into DME and DRUSEN for both the test and train folders. A main goal of this This assignment was completed on Google Colab and all of the code will be tailored towards the syntax of Colab. A thorough dive-in of the code is shown below this general overview list. 

General Overview of the items within the repository:
- 'Assignment2Results': The results from the classifier in Assignment 2. There is a confusion matrix as well as the model loss.
- 'Assignment5Results': The results from the classifier in Assignment 1 but with an input of superresolution images. 
- 'MatthewSanchez_Assignment5.ipynb': Main Google Colab code for this Assignment. It contains all of the necessary code to output the results. There are graphs, directory outputs, model summaries, and more within this code file that should be looked over as the main resource.
- 'README.md': This is the readme file that you are currently reading 
- 'gen_e_120.h5': This is the generator model that was saved after training the SRGAN for 120 epochs. Can be used to predict on the Retinal OCT Images
- 'gen_image0.jpeg': Example Generated Super Resolution image from a 32x32 and original HR image


Dive-in of 'MatthewSanchez_Assignment5.ipynb' code:
- Using Assignment 2 Code to create the 1st model (model A)
1) Importing necessary libraries for code, Mounting the Google Drive and unziping the tiny dataset to the Colab local directory from Assignment 2
2) Split Data into 70/30 ratio and place into new train and val folders. Create a corresponding dataframe for the new train and val folders as well as the orignial test folder
3) For Train, Val, and Test Folders, read through each image files and assign the corresponding DME or DRUSEN labels to each image. This is done with for loop and appending the label to each dataframe
4) Next, the dataframes are converted to a csv
5) A Config class is created to define the parameters of the training process  
6) A custom DataGeneration class is created to load the samples, shuffle, preprocess, and generate the data from the train dataframe csv. 
7) With this custom data generator, the data is loaded and the number of samples for train, test, and val are found. Adiditonally, the images are generated by calling the custom class and the base VGG model is defined. Example output images are shown after the cell
8) The model is then complied and trained. The model is trained fro 20 epochs with inputs fo the train and val data along with the 32 batch size and samples. This model is then saved.
9) With the model saved, a confusion matrix definition is defined preemptively for future use
10) The model is then tested with the test dataframe/data. The model predicts on it and the results are saved for future use. 
11) With the results of the train and validation training, a model loss is plotted and shown
12) Finally, the confusion matrix definition is called and the confusion matrix is plotted with DME and DRUSEN classification results shown 

- START OF ASSIGNMENT 5 CODE
1) To start, the necessary libraries are imported and downloaded
2) All of the images of the 'tiny_data' zip file was combined together into 1 zip and placed in my personal Google Drive.
3) My personal Google Drive was mounted and the Data_Combined_Assignment5.zip was unzipped and stored locally on Google Colab
4) The next important step was to create an SRGAN with the images. To start, 128 images were created by defining a function to resize the original image. This image was appended to a folder by calling the function and the output was saved within a folder in my personal Google Drive. To quality check these images, the number of images were counted and the result (3048 images) was printed below the cell which indicates that we have all of the necessary images. Finally, a random image is displayed to show that the images look correct and are formated correctly. 
5) This same process is done for 32x32 images.
6) All fo these images are then transfered over to my Personal Google Drive for save keeping. This serves as a checkpoint in any case that the code above does not work as intended. A similar code is written to transfer the code from Google Drive to Colab.
7) Next, a wide variety of functions are defined to build the generator, discriminator, and model. The necessary libraries are called throughout the cell to build them.
8) After this, the 32x32 and 128x128 images are sorted to be parallel with one another. Additionally, each image is ensured to be RGB and finally appended to their corresponding list. The list is outputted at the bottom. 
9) An Example image from the each list is shown. The outputted image are the exact same and showcase the 32x32 and the 128x128 versions 
10) The data is then split as np.arrays into lowres_train, lowres_test, highres_train, hr_test variables. From here the shapes and ips are defined and the generator summary is outputted. This is done for the discriminator, VGG model, and GAN model. 
11) The batch size is defined and the training finally begins with 120 epochs
12) After the training is completed, functions have been written to take data trained and their correpsonding models back to Gooogle Drive and Colab. A generator model was saved every 10 epochs since it takes time to train the model. 
13) With the training complete, the model is tested on 1 image to see the results. The results show a superresoltion after 120 epochs of training as well as the low res and original high res image.
14) This cell is then expanded to predict on an entire folder of test data. The images are saved as .jpg and jpeg. These are then saved to my personal Google Drive
15) With these new SuperResoltion Images, the images are then inputted into the Assignment 1/2 Code using the same process as .flowfromdirectory etc.
16) The model is predicted on and the results are stored in a variable. The confusion matrix is defined and generated.
16) Finally the generator loss from the original SRGAN training is plotted and outputted at the bottom  

